{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Scrapy in d:\\app\\python\\377\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in d:\\app\\python\\377\\lib\\site-packages (from Scrapy) (1.1.0)\n",
      "Requirement already satisfied: service-identity>=16.0.0 in d:\\app\\python\\377\\lib\\site-packages (from Scrapy) (21.1.0)\n",
      "Requirement already satisfied: cryptography>=2.0 in d:\\app\\python\\377\\lib\\site-packages (from Scrapy) (3.2.1)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in d:\\app\\python\\377\\lib\\site-packages (from Scrapy) (1.22.0)\n",
      "Requirement already satisfied: setuptools in d:\\app\\python\\377\\lib\\site-packages (from Scrapy) (41.2.0)\n",
      "Requirement already satisfied: protego>=0.1.15 in d:\\app\\python\\377\\lib\\site-packages (from Scrapy) (0.2.1)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in d:\\app\\python\\377\\lib\\site-packages (from Scrapy) (0.6.0)\n",
      "Requirement already satisfied: pyOpenSSL>=16.2.0 in d:\\app\\python\\377\\lib\\site-packages (from Scrapy) (19.1.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in d:\\app\\python\\377\\lib\\site-packages (from Scrapy) (1.6.2)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5; platform_python_implementation == \"CPython\" in d:\\app\\python\\377\\lib\\site-packages (from Scrapy) (2.0.5)\n",
      "Requirement already satisfied: zope.interface>=4.1.3 in d:\\app\\python\\377\\lib\\site-packages (from Scrapy) (5.4.0)\n",
      "Requirement already satisfied: tldextract in d:\\app\\python\\377\\lib\\site-packages (from Scrapy) (3.3.0)\n",
      "Requirement already satisfied: Twisted>=17.9.0 in d:\\app\\python\\377\\lib\\site-packages (from Scrapy) (22.2.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in d:\\app\\python\\377\\lib\\site-packages (from Scrapy) (1.0.4)\n",
      "Requirement already satisfied: lxml>=3.5.0; platform_python_implementation == \"CPython\" in d:\\app\\python\\377\\lib\\site-packages (from Scrapy) (4.8.0)\n",
      "Requirement already satisfied: parsel>=1.5.0 in d:\\app\\python\\377\\lib\\site-packages (from Scrapy) (1.6.0)\n",
      "Requirement already satisfied: six in d:\\app\\python\\377\\lib\\site-packages (from service-identity>=16.0.0->Scrapy) (1.16.0)\n",
      "Requirement already satisfied: pyasn1 in d:\\app\\python\\377\\lib\\site-packages (from service-identity>=16.0.0->Scrapy) (0.4.8)\n",
      "Requirement already satisfied: attrs>=19.1.0 in d:\\app\\python\\377\\lib\\site-packages (from service-identity>=16.0.0->Scrapy) (21.4.0)\n",
      "Requirement already satisfied: pyasn1-modules in d:\\app\\python\\377\\lib\\site-packages (from service-identity>=16.0.0->Scrapy) (0.2.8)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in d:\\app\\python\\377\\lib\\site-packages (from cryptography>=2.0->Scrapy) (1.15.0)\n",
      "Requirement already satisfied: requests-file>=1.4 in d:\\app\\python\\377\\lib\\site-packages (from tldextract->Scrapy) (1.5.1)\n",
      "Requirement already satisfied: requests>=2.1.0 in d:\\app\\python\\377\\lib\\site-packages (from tldextract->Scrapy) (2.27.1)\n",
      "Requirement already satisfied: idna in d:\\app\\python\\377\\lib\\site-packages (from tldextract->Scrapy) (3.3)\n",
      "Requirement already satisfied: filelock>=3.0.8 in d:\\app\\python\\377\\lib\\site-packages (from tldextract->Scrapy) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in d:\\app\\python\\377\\lib\\site-packages (from Twisted>=17.9.0->Scrapy) (4.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 22.1.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Automat>=0.8.0 in d:\\app\\python\\377\\lib\\site-packages (from Twisted>=17.9.0->Scrapy) (20.2.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in d:\\app\\python\\377\\lib\\site-packages (from Twisted>=17.9.0->Scrapy) (21.0.0)\n",
      "Requirement already satisfied: constantly>=15.1 in d:\\app\\python\\377\\lib\\site-packages (from Twisted>=17.9.0->Scrapy) (15.1.0)\n",
      "Requirement already satisfied: incremental>=21.3.0 in d:\\app\\python\\377\\lib\\site-packages (from Twisted>=17.9.0->Scrapy) (21.3.0)\n",
      "Requirement already satisfied: twisted-iocpsupport<2,>=1.0.2; platform_system == \"Windows\" in d:\\app\\python\\377\\lib\\site-packages (from Twisted>=17.9.0->Scrapy) (1.0.2)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in d:\\app\\python\\377\\lib\\site-packages (from itemloaders>=1.0.1->Scrapy) (1.0.0)\n",
      "Requirement already satisfied: pycparser in d:\\app\\python\\377\\lib\\site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.0->Scrapy) (2.21)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in d:\\app\\python\\377\\lib\\site-packages (from requests>=2.1.0->tldextract->Scrapy) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\app\\python\\377\\lib\\site-packages (from requests>=2.1.0->tldextract->Scrapy) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\app\\python\\377\\lib\\site-packages (from requests>=2.1.0->tldextract->Scrapy) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install Scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'tutorial', using template directory 'd:\\app\\python\\377\\lib\\site-packages\\scrapy\\templates\\project', created in:\n",
      "    E:\\CODE\\xiaoyou-bilibili\\python-study\\网络爬虫开发实战\\8.爬虫框架\\tutorial\n",
      "\n",
      "You can start your first spider with:\n",
      "    cd tutorial\n",
      "    scrapy genspider example example.com\n"
     ]
    }
   ],
   "source": [
    "# 我们可以使用下面的命令来新建一个项目\n",
    "!scrapy startproject tutorial"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created spider 'quotes' using template 'basic' in module:\n",
      "  tutorial.spiders.quotes\n"
     ]
    }
   ],
   "source": [
    "# 下面我们先自己手动创建一个爬虫类\n",
    "# 创建一个爬虫类，第一个参数是文件名，第二个参数是爬取的域名\n",
    "!cd tutorial/tutorial && scrapy genspider quotes quotes.toscrape.com"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# 编写好对应的代码后我们运行一下这个爬虫\n",
    "!cd tutorial/tutorial && scrapy crawl quotes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "如果想保存文件可以这样操作\n",
    "\n",
    "![](.8_images/fb7585a5.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 如果想进行更复杂的操作，比如保存到mongoDB中。那么就需要使用pipleLine"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## selector用法"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello word!\n"
     ]
    }
   ],
   "source": [
    "from scrapy import Selector\n",
    "# 这里我们可以手动使用Selector来处理请求\n",
    "body = '<html><head><title>hello word!</title></head><body></body></html>'\n",
    "selector = Selector(text=body)\n",
    "title = selector.xpath('//title/text()').extract_first()\n",
    "print(title)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 我们可以直接使用这种可交互的方式来处理请求\n",
    "!scrapy shell http://doc.scrapy.org/en/latest/_static/selectors-sample1.html\n",
    "# 进入后我们就可以使用交互式的方式来进行操作了\n",
    "# 比如获取一个xpath选择器，这里就获取所有的链接了\n",
    "!result = response.selector.xpath('//a')\n",
    "!result\n",
    "# 然后提取所有的图片节点\n",
    "!result.xpath('./img')\n",
    "# 我们可以单独获取某个元素\n",
    "!result[0]\n",
    "# 如果想提取a节点元素，可以这样\n",
    "!result.extract()\n",
    "# 然后我们尝试一下获取文本\n",
    "!response.xpath('//a/text()').extract()\n",
    "# 可以提取链接\n",
    "!response.xpath('//a/@href').extract()\n",
    "# 下面限定一下范围\n",
    "!response.xpath('//a[@href=\"image1.html\"]/text()').extract()\n",
    "# 上面这个会返回一个数组，我们可以使用下面这个方法来只获取第一个元素\n",
    "!response.xpath('//a[@href=\"image1.html\"]/text()').extract_first()\n",
    "# 还可以设置默认值\n",
    "!response.xpath('//a[@href=\"image1\"]/text()').extract_first('default image')\n",
    "\n",
    "\n",
    "# 下面是css选择器用法，首先我们获取所有a节点\n",
    "!response.css('a')\n",
    "# 下面是属性选择\n",
    "!response.css('a[href=\"image1.html\"]').extract()\n",
    "!response.css('a[href=\"image1.html\"] img').extract()\n",
    "# 统一可以只获取第一个\n",
    "!response.css('a[href=\"image1.html\"] img').extract_first()\n",
    "\n",
    "# 下面是获取文本和属性\n",
    "!response.css('a[href=\"image1.html\"]::text').extract_first()\n",
    "!response.css('a[href=\"image1.html\"] img::attr(src)').extract_first()\n",
    "\n",
    "# 另外xpath和css选择器可以嵌套使用\n",
    "!response.xpath('//a').css('img').xpath('@src').extract()\n",
    "\n",
    "# 这个还支持正则匹配\n",
    "!response.xpath('//a/text()').re('Name:\\s(.*)')\n",
    "\n",
    "# 如果同时存在两个分组，那么就会按序输出\n",
    "!response.xpath('//a/text()').re('(.*?):\\s(.*)')\n",
    "# 正则同样可以只获取第一个\n",
    "!response.xpath('//a/text()').re_first('(.*?):\\s(.*)')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## spider用法\n",
    "\n",
    "![](.8_images/4e0ef44b.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 下载中间件\n",
    "\n",
    "![](.8_images/85e5a11e.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](.8_images/cd680710.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## spider middleware\n",
    "\n",
    "![](.8_images/888dca43.png)\n",
    "\n",
    "![](.8_images/a8f4d677.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## item pipeline用法\n",
    "\n",
    "![](.8_images/e9499076.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}